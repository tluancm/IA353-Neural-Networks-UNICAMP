{"cells":[{"cell_type":"markdown","metadata":{"id":"xMsNyA3WPrER"},"source":["##**Notebook PC#11**\n","\n","## Encoder-Decoder LSTM for Natural Language Processing.\n","\n","**Professor:** Fernando J. Von Zuben <br>\n","**Aluno(a):** Taylon Luan Congio Martins RA: 177379<br>\n","**Aluno(a):** Tiago C A Amorim RA: 100675"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xumdIFHDdrn"},"outputs":[],"source":["from random import seed\n","from random import randint\n","from numpy import array\n","from numpy import argmax"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fspvFmS6Ddro"},"outputs":[],"source":["def random_sum_pairs(n_examples, n_numbers, largest):\n","    X,y = list(), list()\n","    for i in range(n_examples):\n","        in_pattern=[randint(1,largest) for _ in range(n_numbers)]\n","        out_pattern = sum(in_pattern)\n","        X.append(in_pattern)\n","        y.append(out_pattern)\n","    return X,y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzr9HXh8Ddrp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716239064447,"user_tz":180,"elapsed":16,"user":{"displayName":"Taylon","userId":"07833699127766075936"}},"outputId":"dcfde19f-5c08-4bfc-a00d-22d4a79542c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[3, 10]] [13]\n"]}],"source":["seed(1)\n","n_samples =1\n","n_numbers = 2\n","largest = 10\n","X,y = random_sum_pairs(n_samples, n_numbers, largest)\n","print(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QWTgrmmuDdrp"},"outputs":[],"source":["from math import ceil\n","from math import log10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbBlwQTvDdrp"},"outputs":[],"source":["def to_string(X,y,n_numbers,largest):\n","    max_length = n_numbers*ceil(log10(largest+1)) + n_numbers - 1\n","    Xstr = list()\n","    for pattern in X:\n","        strp = '+'.join([str(n) for n in pattern])\n","        strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n","        Xstr.append(strp)\n","    maxlength = ceil(log10(n_numbers*(largest+1)))\n","    ystr = list()\n","    for pattern in y:\n","        strp = str(pattern)\n","        strp = ''.join([' 'for _ in range(maxlength-len(strp))]) + strp\n","        ystr.append(strp)\n","    return Xstr, ystr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAVqEpSsDdrq"},"outputs":[],"source":["seed(1)\n","n_samples = 1\n","n_numbers = 2\n","largest = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-m3UD5uDdrq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716239064447,"user_tz":180,"elapsed":14,"user":{"displayName":"Taylon","userId":"07833699127766075936"}},"outputId":"b6abf880-bb61-4dd7-86a4-4d2c1d8717f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[3, 10]] [13]\n","[' 3+10'] ['13']\n"]}],"source":["X,y = random_sum_pairs(n_samples, n_numbers, largest)\n","print(X,y)\n","\n","X,y = to_string(X,y,n_numbers,largest)\n","print(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwQXLtpfDdrq"},"outputs":[],"source":["alphabet = ['0','1','2','3','4','5','6','7','8','9','+',' ']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXKcXm8JDdrq"},"outputs":[],"source":["def integer_encode(X,y,alphabet):\n","    char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n","    Xenc = list()\n","    for pattern in X:\n","        integer_encoded = [char_to_int[char] for char in pattern]\n","        Xenc.append(integer_encoded)\n","    yenc = list()\n","    for pattern in y:\n","        integer_encoded = [char_to_int[char] for char in pattern]\n","        yenc.append(integer_encoded)\n","    return Xenc, yenc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BjD9y1M2Ddrr"},"outputs":[],"source":["X,y = integer_encode(X,y,alphabet)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v02pwsYYDdrr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716239064448,"user_tz":180,"elapsed":10,"user":{"displayName":"Taylon","userId":"07833699127766075936"}},"outputId":"ae0b4fce-aeb8-4c15-d4b0-6fa75862ea36"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[11, 3, 10, 1, 0]] [[1, 3]]\n"]}],"source":["print(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vad64QkqDdrr"},"outputs":[],"source":["def one_hot_encode(X,y,max_int):\n","    Xenc = list()\n","    for seq in X:\n","        pattern = list()\n","        for index in seq:\n","            vector = [0 for _ in range(max_int)]\n","            vector[index] = 1\n","            pattern.append(vector)\n","        Xenc.append(pattern)\n","\n","    yenc = list()\n","    for seq in y:\n","        pattern = list()\n","        for index in seq:\n","            vector = [0 for _ in range(max_int)]\n","            vector[index] = 1\n","            pattern.append(vector)\n","        yenc.append(pattern)\n","    return Xenc, yenc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_tCfgMPDdrr"},"outputs":[],"source":["X,y = one_hot_encode(X,y,len(alphabet))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7VdCFIgDdrr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716239064448,"user_tz":180,"elapsed":8,"user":{"displayName":"Taylon","userId":"07833699127766075936"}},"outputId":"a181b6a7-3556-4fb3-ce5b-56bf4741a169"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]] [[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]]\n"]}],"source":["print(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xVdn4BqyDdrs"},"outputs":[],"source":["def generate_data(n_samples,n_numbers, largest, alphabet):\n","    X,y = random_sum_pairs(n_samples,n_numbers,largest)\n","    X,y = to_string(X,y,n_numbers,largest)\n","    X,y = integer_encode(X,y,alphabet)\n","    X,y = one_hot_encode(X,y,len(alphabet))\n","    X,y = array(X), array(y)\n","    return X,y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RDp9JqNkDdrs"},"outputs":[],"source":["def invert(seq,alphabet):\n","    int_to_char = dict((i,c) for i,c in enumerate(alphabet))\n","    strings  = list()\n","    for pattern in seq:\n","        string = int_to_char[argmax(pattern)]\n","        strings.append(string)\n","    return ''.join(strings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BqRNPCkDdrs"},"outputs":[],"source":["n_terms = 3\n","largest = 10\n","alphabet = [str(x) for x in range(10)] + ['+', ' ']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PijAMEFxDdrs"},"outputs":[],"source":["n_chars = len(alphabet)\n","n_in_seq_length = n_terms*ceil(log10(largest+1)) +n_terms-1\n","n_out_seq_length = ceil(log10(n_terms*(largest+1)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RR9pPe1oDdrs"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers import RepeatVector\n","from keras.layers import TimeDistributed\n","from keras.layers import Dense"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gxs5FSIwDdrs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716239071260,"user_tz":180,"elapsed":1560,"user":{"displayName":"Taylon","userId":"07833699127766075936"}},"outputId":"d50d3ff2-0366-40d1-cb5a-dadebaa031c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 75)                26400     \n","                                                                 \n"," repeat_vector (RepeatVecto  (None, 2, 75)             0         \n"," r)                                                              \n","                                                                 \n"," lstm_1 (LSTM)               (None, 2, 50)             25200     \n","                                                                 \n"," time_distributed (TimeDist  (None, 2, 12)             612       \n"," ributed)                                                        \n","                                                                 \n","=================================================================\n","Total params: 52212 (203.95 KB)\n","Trainable params: 52212 (203.95 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["model = Sequential()\n","model.add(LSTM(75, input_shape=(n_in_seq_length,n_chars)))\n","model.add(RepeatVector(n_out_seq_length))\n","model.add(LSTM(50,return_sequences=True))\n","model.add(TimeDistributed(Dense(n_chars,activation='softmax')))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vG1QwiwFDdrt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716239137117,"user_tz":180,"elapsed":65863,"user":{"displayName":"Taylon","userId":"07833699127766075936"}},"outputId":"15ce165f-7b04-4ee7-e0af-af3705738cd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["7500/7500 [==============================] - 55s 6ms/step - loss: 0.4088 - accuracy: 0.8780\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a5ada3c19f0>"]},"metadata":{},"execution_count":21}],"source":["X,y = generate_data(75000,n_terms,largest,alphabet)\n","model.fit(X,y,epochs=1,batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBWMp85oDdrt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716239138196,"user_tz":180,"elapsed":1083,"user":{"displayName":"Taylon","userId":"07833699127766075936"}},"outputId":"c2b93ae2-d37f-4edf-c2a7-289853052006"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 0.032466, Accuracy: 100.000000\n"]}],"source":["X,y = generate_data(100,n_terms,largest,alphabet)\n","loss,acc = model.evaluate(X,y,verbose=0)\n","print('Loss: %f, Accuracy: %f' %(loss,acc*100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XjorRbDxDdrt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716239139551,"user_tz":180,"elapsed":1366,"user":{"displayName":"Taylon","userId":"07833699127766075936"}},"outputId":"f86380a0-4017-4c47-e51f-9c44173d50fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["   3+7+5 = 15 (expect 15)\n","  2+10+6 = 18 (expect 18)\n","   4+5+9 = 18 (expect 18)\n","   2+2+4 =  8 (expect  8)\n"," 10+7+10 = 27 (expect 27)\n","  10+2+3 = 15 (expect 15)\n","   8+4+1 = 13 (expect 13)\n","   8+1+3 = 12 (expect 12)\n","   5+9+6 = 20 (expect 20)\n","   1+5+8 = 14 (expect 14)\n"]}],"source":["for _ in range(10):\n","    X,y = generate_data(1,n_terms,largest,alphabet)\n","    yhat = model.predict(X,verbose=0)\n","    in_seq = invert(X[0],alphabet)\n","    out_seq = invert(y[0],alphabet)\n","    predicted = invert(yhat[0],alphabet)\n","    print('%s = %s (expect %s)' %(in_seq,predicted,out_seq))"]},{"cell_type":"markdown","source":["<font color=\"green\">\n","Atividade (a) <br>\n","Como são gerados os dados de treinamento?\n","</font>"],"metadata":{"id":"mulXq9ZZKkX5"}},{"cell_type":"markdown","source":["**Resposta:**<br>\n","Os dados são gerados a partir de exemplos aleatórios de somas de inteiros, que são convertidos a sequências de elementos de um dicionário one-hot. É utilizada a função **generate_data()**, a qual realiza as seguintes transformações sequenciais nos dados a serem gerados:\n","\n","**random_sum_pairs()**: cria um dataset de pares input-output, onde cada input é uma lista de inteiros aleatórios e cada output é a soma dos inteiros correspondentes.\n","\n","**to_string()**: converte os dados numéricos criados em dados formatados como string.\n","\n","**integer_encode()**: converte a string de caracteres em uma lista de inteiros baseados num alfabeto passado como parâmetro, no caso, o alfabeto utilizado é composto por: [“0”, “1”, “2”, “3”, “4”, “5”, “6”, “7”, “8”, “9”, “+”, “ “].\n","\n","**one_hot_encode()**: converte a sequência de inteiros em uma representação one-hot-encoding que são vetores de dimensão do alfabeto (1x12) onde cada caractere é representado por um conjunto de zeros e um único valor 1.\n","\n","**array()**: por fim, os dados de treinamento input-output são transformados em formato array da biblioteca numpy para serem ingeridos pelo modelo de aprendizado de máquina."],"metadata":{"id":"BGsvW_2eTpfB"}},{"cell_type":"markdown","source":["<font color=\"green\">\n","Atividade (b) <br>\n","Como uma calculadora simples pode operar baseada no conceito de tradução de frases, ou seja, sem realizar operações algébricas?\n","</font>"],"metadata":{"id":"Fn1TbpOT_ew-"}},{"cell_type":"markdown","source":["**Resposta:**<br>\n","Utilizando o conceito de NLP, como neste notebook, é possível criar um modelo seq2seq onde dado um token (e por fim uma sequência de tokens) que pertence a um dicionário definido a priori, o modelo gera uma saída esperada, também sequencial, este é o princípio básico da operação de alguns tradutores. Uma arquitetura com bloco LSTM, cuja arquitetura é recorrente e possui dinâmica não-linear, consegue capturar dependências sequenciais dos dados de entrada por processarem os token de maneira sequencial e atualizarem seus estados internos baseados no tokens anteriores, isto ocorre porque no treinamento a máquina aprende a mapear sequências de entrada para sequências de saída. No exemplo, o dicionário é composto de números inteiros (“0...9”), acrescido do símbolo de operação de soma (“+”) e de espaço (“ “). Portanto, quando entramos com uma sequência como 3+7+5 a máquina consegue inferir a o valor 15, funcionando como uma calculadora.\n","\n","Este modelo tem algumas limitações ao usar o one-hot-encoding como: alta dimensão e esparcialidade dos dados que não capturam semântica entre tokens, falta de contexto no embedding dos tokens.  \n","\n","Para um dicionário pequeno (igual ao do notebook), este modelo e arquitetura são suficientes para bons resultados. Para uma calculadora mais complexa, com mais operações, pode-se ter que recorrer a arquiteturas mais avançadas como transformers, que possui mecanismo de self-attention e conseguem gerar um word-embedding que guarde relações semânticas e de contexto entre tokens.\n","\n","\n","\n","A estrutura da rede foi desenhada para que consiga gerar uma sequência de saída em função de uma sequência de entrada. O que se espera da rede é que consiga inferir as relações semânticas entre os elementos que constituem cada sequência de entrada, como ignorar espaços no início e juntar dígitos para formar um número.\n","\n","Em uma rápida análise, é possível que a rede tenha ‘decorado’ todas possíveis sequências. A base de dados foi construída por 75000 sequências, mas temos um total de 10^3=1000 possíveis sequências para o problema colocado. Desta forma, várias sequências se repetem na base de dados montada, e é grande a probabilidade de que todas as possíveis combinações fazem parte da base de dados. Aumentando o maior inteiro possível o problema fica bem mais difícil para a rede resolver, e a acurácia cai substancialmente:\n","\n","Máximo=50, dados de treino ~50% do universo, acurácia de teste=70%.\n","\n","Máximo=99, dados de treino ~7,5% do universo, acurácia de teste=60%.\n","\n","Mesmo errando o valor da soma, a rede estima uma resposta próxima do valor real. Ou seja, a rede consegue representar as distâncias entre as sequências de saída como distâncias entre os inteiros que representam."],"metadata":{"id":"8xRF9vul_ew_"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}